# Creative-LLM

一个用于研究大语言模型在结构化生成任务中表现的项目。这个项目探索了LLM在三种不同类型任务下的表现：布尔表达式生成、3D结构生成和因果链推理。

## 环境配置

```shell
# cd creative-llm
uv sync
```

## Boolean Expression 任务

在布尔表达式生成任务中，我们基于TinyLlama进行了一系列改进。最开始，模型在理解布尔逻辑方面表现不太理想，经常生成语法错误的表达式或无法满足给定约束的表达式。

通过深入分析发现，主要问题出在两个方面：1) 模型对布尔代数的基本概念理解不够深入；2) 生成的表达式往往过于复杂，包含许多冗余项。

为了解决这些问题，我们采用了两种方法：

首先尝试了传统的prompt engineering方法。通过精心设计提示模板，加入了更多关于布尔代数基础知识的上下文信息，并要求模型在生成表达式前先分析输入输出对的规律。这种方法在提高表达式合法性方面就有了不错的效果。

不过光靠prompt engineering还不够。我们后来用GRPO（Generative Reward Promoting Optimization）方法来微调模型。关键是设计了一个多维度的奖励函数，不仅考虑表达式的正确性，还考虑了表达式的简洁性和创新性。比如说模型要是能找到比ground truth更简单的等价表达式，我们会给额外的奖励分。

经过这些改进，模型现在能相当稳定地生成简洁、正确的布尔表达式了。从实验结果看，prompt engineering和GRPO的结合效果特别好，不仅提高了成功率，还让模型能发现一些很优雅的表达式形式。

不过现在还有一些有意思的问题值得继续研究，比如如何引导模型发现更多语义等价但形式不同的表达式，以及如何在保持正确性的同时进一步降低表达式的复杂度。这些问题我后面打算继续深入研究。

[未完待续...]