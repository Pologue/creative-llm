llm:
  type: local
  models:
    openrouter: Null
    openai: Null
    anthropic: Null
    local: "/opt/data/private/FYP33_OYXX/LLaMA-Factory/output/qwen3_Thinking_lora_sft_5epoch" # "/opt/data/private/FYP33_OYXX/MODEL/Qwen/Qwen3-4B-Instruct-2507"
  api_keys:
    openrouter: ""
    openai: ""
    anthropic: ""
  temperature: 0.7

benchmark:
  checkpoint: "checkpoints"
  verbose: true
  output_pattern: "results/{dataset_name}_{model}.json"
